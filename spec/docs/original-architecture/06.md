## 6. Lifecycle Management

Having established the architectural layers, we now examine the complete lifecycle of resources, indices, and installations - from initial Pod setup through daily operations to long-term maintenance and cleanup.

### 6.1. Pod Setup and Initial Configuration

When an application first encounters a Pod, it may need to configure the Type Index and other Solid infrastructure. The framework provides standard templates for this initialization process (see [templates/README.md](../templates/README.md) for complete placeholder substitution documentation):

**Comprehensive Setup Process:**
1. Check WebID Profile Document for solid:publicTypeIndex
2. If found, query Type Index for required managed resource registrations (sync:ManagedDocument with sync:managedResourceType schema:Recipe, idx:FullIndex, crdt:ClientInstallation, etc.)
3. Collect all missing/required configuration:
   - Missing Type Index entirely
   - Missing Type Registrations for managed data types (sync:ManagedDocument)
   - Missing Type Registrations for indices  
   - Missing Type Registrations for installations
4. If any configuration is missing: Display single comprehensive "Pod Setup Dialog"
5. User chooses approach:
   1. **"Automatic Setup"** - Configure Pod with standard paths automatically
   2. **"Custom Setup"** - Review and modify proposed Profile/Type Index changes before applying
6. If user cancels: Run with hardcoded default paths, warn about reduced interoperability

**Setup Dialog Design Principles:**
- **Explicit Consent:** Never modify Pod configuration without user permission
- **Progressive Disclosure:** Automatic Setup shields users from complexity, Custom Setup provides full control
- **Clear Options:** Two main paths - trust the app or customize the details
- **Graceful Fallback:** Always offer alternative approaches if user declines configuration changes

**Example Setup Flow:**
```
1. Discover missing Type Index registrations for sync:ManagedDocument with sync:managedResourceType schema:Recipe
2. Present setup dialog: "This app needs to configure CRDT-managed recipe storage in your Pod"
3. User selects "Automatic Setup"
4. App creates Type Index entries for managed recipes, recipe index, client installations
5. App proceeds with normal synchronization workflow
```

### 6.2. Installation Document Creation

After successful Pod setup, the framework automatically creates an Installation Document (`crdt:ClientInstallation`) to represent this specific client installation in the collaborative system. This document establishes the installation's identity and enables collaborative coordination with other installations.

**Lifecycle Role:**
The Installation Document serves as the foundation for all collaborative operations - index management, dormancy detection, and CRDT conflict resolution. It is registered in the system Installation Index and remains active until the installation is tombstoned.

**Tombstoned Installation Recovery:**
If an installation discovers its own document has been tombstoned (`max(crdt:deletedAt) > max(crdt:createdAt)`) **or cannot find its installation document remotely** (indicating it was tombstoned and later garbage collected), it must **not** attempt undeletion or continue using the stored installation ID. Instead, it creates a fresh installation identity and resets all internal state.

**Recovery Process:**
1. **Detection during startup:** Framework checks if its locally stored installation ID exists in the remote Installation Index
2. **Scenario A - Document found but tombstoned:** Proceed with fresh start
3. **Scenario B - Document not found:** Assume it was tombstoned and garbage collected, proceed with fresh start
4. **User notification:** Inform user that "this installation was deactivated due to inactivity and will be reset"
5. **Fresh start:** Generate new installation ID and reset all local caches/state
6. **Clean re-sync:** Re-synchronize all data from Pod with fresh collaborative state

**Critical Policy:**
An installation that has a locally stored installation ID but cannot find that specific ID in the remote Installation Index must assume it was tombstoned and subsequently garbage collected. It must **not** continue using the stored ID or attempt to recreate a document with that same ID - it must generate a completely new installation ID.

This approach ensures system integrity and prevents "zombie" installations from creating CRDT conflicts.

**Details:** See Section 4.2 for complete Installation Document specification, properties, and CRDT behavior.

### 6.3. System Index Setup

Before application-specific functionality can begin, the framework establishes essential system indices required for collaborative coordination and maintenance operations.

**Required System Indices:**
- **Installation Index:** For tracking all client installations (Section 4.2.2)
- **Framework Garbage Collection Index:** For tracking tombstoned documents (Section 6.6)

**Lifecycle Role:**
These indices follow standard creation and discovery rules (Chapter 4) but are established automatically during framework initialization. The Installation Index receives the installation document created in Section 5.2, enabling collaborative operations for subsequent application indices.

**Creation Timing:**
System indices are created before application indices to ensure the collaborative infrastructure is ready when applications begin data synchronization.

### 6.4. Application Index Setup

With system indices established, the framework creates application-specific indices based on the data types the application needs to synchronize. Applications declare their requirements and the framework establishes the appropriate index patterns (FullIndex or GroupIndexTemplate) following the rules in Chapter 4.

**Lifecycle Role:**
Application indices are created during startup or when first accessing new data types. The framework coordinates creation collaboratively - discovering existing compatible indices before creating new ones, and ensuring all installations can participate in the collaborative indexing.

**Synchronization Priority:**
All **required** application indices must be synchronized and merged before exposing functionality to users, ensuring consistent application state across installations. However, applications that can handle incomplete data may choose to use indices still in populating state, with the understanding that results will be incrementally complete as population progresses.

**Details:** See Chapter 4 for complete indexing patterns, creation rules, and collaborative coordination mechanisms.

### 6.5. Resource Creation and Naming

Once Pod setup is complete and all required system and application indices are established and synchronized, applications can begin creating data resources. Resource naming is a critical design decision that affects both performance and maintainability, requiring careful consideration of Pod filesystem limitations and RDF principles.

**The Performance Challenge:**
Most Pod servers (including Community Solid Server) use filesystem backends that can experience performance degradation with thousands of files in a single directory. While the framework uses sophisticated sharding for indices, data resources still need thoughtful organization.

**Fundamental Principle: IRIs Must Be Stable**
Resource IRIs are **identifiers**, not storage locations. Any organizational structure must derive from **invariant properties** of the resource that will never change. Changing IRIs breaks references and violates RDF principles.

**Recommended Naming Approaches:**

**1. Semantic Organization (Preferred)**
Structure paths based on meaningful, invariant properties:
```turtle
# By semantic category (if immutable)
/data/recipes/cuisine/italian/pasta-carbonara
/data/recipes/cuisine/mexican/tacos-al-pastor

# By creation date (if relevant and stable)
/data/shopping-entries/created/2024/08/weekly-shopping-list-001
/data/journal-entries/created/2024/08/15/morning-reflection
```

**2. UUID-Based Distribution (For Large Datasets)**
For UUID-based identifiers, use prefix-based distribution:
```turtle
# UUID: af1e2d43-3ed4-4f5e-9876-1234567890ab
/data/resources/af/1e/af1e2d43-3ed4-4f5e-9876-1234567890ab

# Benefits: Predictable, evenly distributed, derived from invariant UUID
```

**3. Flat Structure (Small Datasets)**
For small collections (< 1000 resources), flat structure is acceptable:
```turtle
/data/recipes/tomato-soup-recipe
/data/recipes/pasta-carbonara-recipe
```

**Strategy Comparison:**

| Strategy | Best For | Performance | Discoverability | Trade-offs |
|----------|----------|-------------|-----------------|------------|
| **Semantic** | Human browsing, meaningful categories | Complex path computation, potential hotspots | High - paths are human-readable | Reorganization complexity if categories change |
| **UUID** | High throughput, even distribution | Optimal - predictable, evenly distributed | Low - requires index for discovery | Loss of human-readable structure |
| **Flat** | Small datasets, simple apps | Good for <1000 resources | Medium - browsable but no structure | Degrades with scale, directory limits |

**Resource Creation Workflow:**
1. **Generate stable IRI** using chosen naming strategy
2. **Determine target indices** - Identify all matching index shards based on:
   - Resource type
   - Group membership for GroupIndexTemplate patterns (resources may belong to multiple groups)  
   - Active shard status (exclude tombstoned or deleted shards)
3. **Prepare resource document** with semantic data, CRDT metadata, and `idx:belongsToIndexShard` links to target shards
4. **Upload resource document** to Pod storage
5. **Update index shards** - Add index entries to all target shards and upload updated shards to Pod (may be batched when creating multiple resources together)
6. **Resumption mechanism** - Implementations should track workflow state to resume interrupted operations at any step

**Fault Tolerance:**
Resource creation must be resumable after interruptions (network failures, app termination, etc.). The workflow is designed so each step can be retried independently, with the resource document serving as the source of truth for which shards need updating.

**Critical Guidelines:**
- **Never change IRIs**: Once published, IRIs are permanent identifiers - even if underlying properties change
- **Derive from invariants**: Path structure should be based on properties unlikely to change, but IRI stability takes precedence over semantic accuracy
- **Plan for scale**: Consider performance implications of naming choices early
- **Accept semantic drift**: If "invariant" properties do change, maintain the existing IRI and let CRDT merge behavior handle the data updates


### 6.6. Framework Garbage Collection Index

System-level index for tracking documents with deletion timestamps that require proactive cleanup. This includes temporary framework documents (populating shards) and complete user data documents marked for deletion, but **not property tombstones** which are handled during sync-time processing.

#### 6.6.1. Design and Structure

**Centralized Cleanup Strategy:**
Rather than scanning entire data containers, framework-managed documents with ANY `crdt:deletedAt` timestamp are automatically registered in this index. The cleanup process evaluates `max(crdt:deletedAt) > max(crdt:createdAt)` using indexed temporal data to determine actual deletion state.

**GroupIndexTemplate Configuration:**
```turtle
<gc-index-template> a idx:GroupIndexTemplate;
   sync:isGovernedBy mappings:index-v1;
   idx:indexesClass sync:ManagedDocument, idx:FullIndex, idx:GroupIndex, 
                    idx:GroupIndexTemplate, idx:Shard;  # Framework types only
   idx:indexedProperty [
     idx:trackedProperty crdt:deletedAt, crdt:createdAt;  # Temporal evaluation
     idx:readBy <installation-uri>
   ], [
     idx:trackedProperty rdf:type, sync:managedResourceType, idx:indexesClass;  # Retention policies
     idx:readBy <installation-uri>
   ];
   idx:groupedBy [
     a idx:GroupingRule;
     idx:property [
       idx:sourceProperty crdt:deletedAt;
       idx:transform (
         [
           a idx:RegexTransform;
           idx:pattern "^([0-9]{4})-[0-9]{2}-[0-9]{2}$";
           idx:replacement "${1}"
         ]
       ) .
       # No idx:missingValue = only documents with deletedAt get indexed
     ];
     # No groupTemplate - paths generated deterministically as: gc/{yyyy}/index
   ];
   idx:shardingAlgorithm [
     a idx:ModuloHashSharding;
     idx:hashAlgorithm "md5";
     idx:numberOfShards 1
   ];
   idx:populationState "active";
   idx:readBy <installation-uri> .
```

**Registration Behavior:**
- **Active documents** (no `crdt:deletedAt`): Not indexed
- **Documents with deletion timestamps**: Registered in yearly groups (`gc/2024/index`, etc.)
- **Undeletion handling**: Documents removed from GC index when `crdt:deletedAt` property tombstones are cleaned up

#### 6.6.2. Cleanup Operations

**Document Garbage Collection Process:**
1. **Periodic scans**: Background processes scan GC index groups older than retention periods
2. **Temporal validation**: Verify `max(crdt:deletedAt) > max(crdt:createdAt)` using indexed data
3. **Retention verification**: Apply type-specific retention periods using (`rdf:type`, `sync:managedResourceType`) or (`rdf:type`, `idx:indexesClass`) tuples
4. **Document deletion**: Remove document files from Pod (fragment resources already removed during tombstoning)
5. **Index maintenance**: Remove entries for successfully deleted documents from GC index

**Implementation Guidelines:**
- **Batch processing**: 50-100 documents per cycle, 2-5 minutes max execution time
- **Frequency**: Every 24-48 hours during low-activity periods
- **Concurrent safety**: Multiple installations coordinate through CRDT merge rules
- **Universal emptying benefits**: Tombstoned documents already have minimal size and no application index references

**Efficiency Benefits:**
- No container scanning required
- Type-aware retention policies
- Centralized deletion timestamp tracking
- Batch operations optimize Pod performance

### 6.7. Retention Policies and Cleanup Configuration

The framework provides configurable retention policies for tombstoned documents, recognizing their different cleanup strategies and risk profiles.

**Cleanup Configuration Properties:**

**Document Tombstone Configuration:**
- **`crdt:documentTombstoneRetentionPeriod`:** Duration to retain deleted documents (recommended: P2Y)
- **`crdt:enableDocumentTombstoneCleanup`:** Whether to automatically clean up document tombstones
- **Cleanup Strategy:** Proactive cleanup via Framework Garbage Collection Index (see Section 6.6)
- **Risk:** Zombie deletions can affect recreated documents with same IRI

**Property Tombstone Configuration:**
- **`crdt:propertyTombstoneRetentionPeriod`:** Duration to retain deleted property values (recommended: P6M to P1Y)
- **`crdt:enablePropertyTombstoneCleanup`:** Whether to automatically clean up property tombstones
- **Cleanup Strategy:** Sync-time cleanup during document processing (not tracked in GC index)
- **Risk:** Deleted property values may reappear, but document remains intact

**Configuration Hierarchy:**

**Framework Defaults Hierarchy:**
1. **Type Index defaults:** Cleanup properties on the Type Index document itself
2. **Type-specific overrides:** Individual registrations can override Type Index defaults  
3. **User control:** Framework never overwrites existing user-configured values

**Example Type Index Configuration:**
```turtle
# Type Index with framework-wide defaults
<> a solid:TypeIndex;
   # Framework adds these defaults if missing
   crdt:documentTombstoneRetentionPeriod "P2Y"^^xsd:duration;
   crdt:enableDocumentTombstoneCleanup true;
   crdt:propertyTombstoneRetentionPeriod "P6M"^^xsd:duration;
   crdt:enablePropertyTombstoneCleanup true;
   solid:hasRegistration [
      a solid:TypeRegistration;
      solid:forClass sync:ManagedDocument;
      sync:managedResourceType schema:Recipe;
      solid:instanceContainer <../data/recipes/>;
      # Override: Keep recipe document tombstones longer
      crdt:documentTombstoneRetentionPeriod "P3Y"^^xsd:duration;
      crdt:propertyTombstoneRetentionPeriod "P3M"^^xsd:duration
   ] .
```

**Cleanup Strategies:**

**Document Tombstone Cleanup (Proactive):**
1. **Registration:** Complete tombstoned documents automatically registered in Framework Garbage Collection Index
2. **Discovery:** Cleanup processes scan GC index for documents older than retention period
3. **Processing:** Remove entire document files from Pod after verifying retention requirements
4. **Efficiency:** No need to scan data containers for tombstoned documents

**Property Tombstone Cleanup (Sync-Time):**
1. **Integration:** Property tombstone cleanup happens during normal document synchronization
2. **Detection:** When syncing a document, check all property tombstones against retention configuration
3. **Local Processing:** Clean expired property tombstones as part of document merge process
4. **Benefits:** Documents not actively synced retain their tombstones (may be beneficial for long-term auditability)
5. **Trade-offs:** Only synchronized documents are cleaned, unused documents accumulate stale tombstones

### 6.8. Collaborative Index Lifecycle Management

All index lifecycle decisions are made collaboratively through CRDT-managed installation documents and index properties, eliminating single points of failure and coordination bottlenecks.

#### 6.8.1. Reader Management and Cleanup

**Reader Tracking:**
```turtle
<> a idx:FullIndex;
   sync:isGovernedBy mappings:index-v1;
   idx:indexedProperty [
     idx:trackedProperty schema:name;
     idx:readBy <installation-1>, <installation-2>  # OR-Set of active readers
   ];
   idx:readBy <installation-1>, <installation-2>, <installation-3> .  # Index-level readers
```

**Collaborative Cleanup Process:**
1. **Installation tombstoning**: Remove tombstoned installations from all `idx:readBy` OR-Sets
2. **Property cleanup**: Remove properties with empty `idx:readBy` lists from `idx:indexedProperty`
3. **Index tombstoning**: Tombstone indices when `idx:readBy` becomes empty
4. **Garbage collection**: Tombstoned indices enter GC index for cleanup after retention period

#### 6.8.2. Index States and Reactivation

**Index States:**
- **Active**: `idx:populationState "active"`, non-empty `idx:readBy` list, receives updates
- **Tombstoned**: When `idx:readBy` becomes empty, index is tombstoned by setting `crdt:deletedAt`, then registered in GC index for cleanup

**Reactivation Process:**
When discovering compatible tombstoned indices:
1. **Undelete**: Add new `crdt:createdAt` timestamp, tombstone existing `crdt:deletedAt` entries
2. **Fresh initialization**: Recreate index structure from scratch as if it never existed before
3. **Join as reader**: Add installation to `idx:readBy` OR-Set
4. **Fresh population**: Set `idx:populationState "populating"` and perform complete index population like a new index


### 6.9. Error Handling and Recovery

The framework provides robust error handling for lifecycle management failures, ensuring system integrity and recovery from various failure scenarios. For comprehensive error handling patterns and implementation guidance, see [ERROR-HANDLING.md](ERROR-HANDLING.md).

#### 6.9.1. Recovery Principles

**Fundamental Approaches:**
- **Fail-safe defaults**: When in doubt, choose options that preserve data integrity
- **Incremental recovery**: Break operations into small, resumable steps to handle interruptions
- **Fresh start preference**: For complex failures, rebuild from scratch rather than attempting partial repairs
- **CRDT-based coordination**: Use existing CRDT merge rules to resolve conflicts during recovery

#### 6.9.2. Key Recovery Scenarios

**Pod Setup Recovery:**
- **Incomplete setup**: Re-present setup dialog for missing Type Index entries
- **Permission failures**: Offer alternative approaches (local-only operation, manual configuration)
- **Network interruptions**: Resume from last completed step, avoid duplicate operations

**Index Lifecycle Recovery:**
- **Reactivation failures**: Restart with clean tombstoned state and perform fresh population
- **Population interruptions**: Resume index population from last successfully processed resource
- **Concurrent conflicts**: Use CRDT merge rules when multiple installations perform recovery simultaneously

**Garbage Collection Recovery:**
- **Cleanup interruptions**: Queue failed operations for retry with exponential backoff
- **GC index corruption**: Accept orphaned tombstoned documents as manageable trade-off (universal emptying keeps them minimal)
- **Cross-validation**: Validate GC index entries against document states only during normal processing, avoid expensive container scans

**Property Tombstone Recovery:**
- **Malformed tombstones**: Detect and repair tombstones with invalid RDF structure
